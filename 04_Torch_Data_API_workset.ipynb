{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LST--PuAXxvU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "from torch import nn\n",
        "import os\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from multiprocessing import cpu_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irHkC09MZIYs"
      },
      "outputs": [],
      "source": [
        "# Load data into memory\n",
        "# These datasets come come pre-packaged with colab, so it's best to run this lesson there.\n",
        "housing = pd.read_csv('sample_data/california_housing_train.csv')\n",
        "housing_test = pd.read_csv('sample_data/california_housing_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAhOBwfBcrgg"
      },
      "outputs": [],
      "source": [
        "housing.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlIjCGoPmLmW"
      },
      "outputs": [],
      "source": [
        "housing.agg(['mean','std'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwbCL-mzdHHE"
      },
      "outputs": [],
      "source": [
        "x_train = housing.drop('median_house_value', axis=1)\n",
        "y_train = housing.median_house_value.values\n",
        "\n",
        "x_valid = housing_test.drop('median_house_value', axis=1)\n",
        "y_valid = housing_test.median_house_value.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2k1dpohdMCQ"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_valid_scaled = scaler.transform(x_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrVbqzsMmgJx"
      },
      "outputs": [],
      "source": [
        "# Check that the means of each column are close to 0\n",
        "assert np.allclose(x_train_scaled.mean(axis=0), np.zeros(x_train_scaled.shape[1]))\n",
        "# Check that the stds of each column are close to 1\n",
        "assert np.allclose(x_train_scaled.std(axis=0), np.ones(x_train_scaled.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2T2J0jz7dX9s"
      },
      "outputs": [],
      "source": [
        "class HousingDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        super().__init__()\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        # What are some other ways we could do this?\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pw23weTVdgH_"
      },
      "outputs": [],
      "source": [
        "train_ds = HousingDataset(x_train_scaled, y_train)\n",
        "valid_ds = HousingDataset(x_valid_scaled, y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oa_dtzmE7XAP"
      },
      "outputs": [],
      "source": [
        "# What are the number of items in each dataset?\n",
        "len(train_ds), len(valid_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvJh9XDue1wt"
      },
      "outputs": [],
      "source": [
        "# What is the x and y at a given index?\n",
        "idx = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taVAR13Cd8Bv"
      },
      "outputs": [],
      "source": [
        "x, y = train_ds[idx]\n",
        "x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FihpdFn5o6ps"
      },
      "outputs": [],
      "source": [
        "# Choose an index in your dataset\n",
        "idx = ...\n",
        "# Fetch an item at that index from train_ds\n",
        "x, y = ...\n",
        "# check that the x value is the same as the corresponding value from x_train_scaled at the same index\n",
        "assert ...\n",
        "# check that the y value is the same as the corresponding value from y_train at the same index\n",
        "assert ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFYhFSjl8v1E"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "N_WORKERS = cpu_count()\n",
        "print(f\"\"\"\n",
        "In this example, each batch will contain {BATCH_SIZE} items.\n",
        "We will use {N_WORKERS} workers to load data more efficiently.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f__XXpSqegyG"
      },
      "outputs": [],
      "source": [
        "train_dl = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True, # We generally want to shuffle the train dataloader\n",
        "    num_workers=N_WORKERS\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_fIo1Faqm03"
      },
      "outputs": [],
      "source": [
        "valid_dl = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUxUSvzcfWVK"
      },
      "outputs": [],
      "source": [
        "# Pull one batch of data\n",
        "for batch in train_dl:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCn6xuYorbD9"
      },
      "outputs": [],
      "source": [
        "# What's the type? The length?\n",
        "type(batch), len(batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2l6lnnNBrhKt"
      },
      "outputs": [],
      "source": [
        "# This looks like our X\n",
        "batch[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Yz1yxGnrkFy"
      },
      "outputs": [],
      "source": [
        "# This looks like our y\n",
        "batch[1].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCJxT_7jAxSU"
      },
      "outputs": [],
      "source": [
        "for x_batch, y_batch in train_dl:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rbn83vLAgJ7"
      },
      "outputs": [],
      "source": [
        "x_batch.shape, y_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5HxCHYefX1P"
      },
      "outputs": [],
      "source": [
        "x_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmN0W7NCfYS7"
      },
      "outputs": [],
      "source": [
        "y_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vl-rx_cWHWcq"
      },
      "outputs": [],
      "source": [
        "# We're just using fastai for the datasets for now.\n",
        "# We'll learn how to use it for modeling later on.\n",
        "!pip install -Uqq fastai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-9Hlz_jDPRZ"
      },
      "outputs": [],
      "source": [
        "# Download and extract the data\n",
        "from fastai.data.all import URLs, untar_data\n",
        "from fastcore.basics import Path\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "path = untar_data(URLs.CIFAR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vb5KvV4GJ2D_"
      },
      "outputs": [],
      "source": [
        "# what files or directories are in the path variable?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHtDPxWbJ6In"
      },
      "outputs": [],
      "source": [
        "# what is contained in path/'train'?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtBvqzCgJ-j4"
      },
      "outputs": [],
      "source": [
        "# find the paths for 10 images of airplanes from the train dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJA4e2agJIIj"
      },
      "outputs": [],
      "source": [
        "def list_png_files(path):\n",
        "    return list(path.glob('**/*.png'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1ltVn2VG_HU"
      },
      "outputs": [],
      "source": [
        "sample_files = list_png_files(path/'train')[:10]\n",
        "sample_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLqc9xFQI_fk"
      },
      "outputs": [],
      "source": [
        "def label_from_path_parent(path:Path) -> str:\n",
        "    return path.parent.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-mb_cpQz6E0"
      },
      "outputs": [],
      "source": [
        "# Sanity check for label_from_parent_path\n",
        "assert label_from_path_parent(Path('/root/.fastai/data/cifar10/train/horse/42500_horse.png')) == 'horse'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvvZpZNPJwh5"
      },
      "outputs": [],
      "source": [
        "def load_image_and_label(path):\n",
        "    img = Image.open(path)\n",
        "    label = label_from_path_parent(path)\n",
        "    return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTsKfGM4J6Pq"
      },
      "outputs": [],
      "source": [
        "img, label = load_image_and_label(sample_files[0])\n",
        "print(label)\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dF7O4ggkKLAX"
      },
      "outputs": [],
      "source": [
        "# Let's resize this image and inspect what it looks like\n",
        "img.resize((224,224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPDJO3iwJpmC"
      },
      "outputs": [],
      "source": [
        "class CifarDataset(Dataset):\n",
        "    def __init__(self, path):\n",
        "        self.path = path\n",
        "        self.files = ...\n",
        "\n",
        "    def __len__(self):\n",
        "        return ...\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuPZ_aVKK6za"
      },
      "outputs": [],
      "source": [
        "train_cifar = CifarDataset(path/'train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DouJ2oSAK-lw"
      },
      "outputs": [],
      "source": [
        "img, label = train_cifar[8000]\n",
        "print(label)\n",
        "img.resize((224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60Q6K78pLVl3"
      },
      "outputs": [],
      "source": [
        "def img_to_scaled_tensor(img, channels_first=True):\n",
        "    t = torch.tensor(np.array(img) / 255).float()\n",
        "    if channels_first:\n",
        "        return t.permute(2, 0, 1)\n",
        "    return t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6Wi6oVXNjSE"
      },
      "outputs": [],
      "source": [
        "img_t = img_to_scaled_tensor(img)\n",
        "img_t.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxjgnzKIL14w"
      },
      "outputs": [],
      "source": [
        "classes = {d.name:i  for i, d in enumerate((path/'train').ls())}\n",
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qZYHzV9MA7t"
      },
      "outputs": [],
      "source": [
        "def class_to_idx(class_name):\n",
        "    return classes.get(class_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feO5VhKBMdsH"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    # The batch comes in the format ((x1, y1), (x2, y2), ..., (xn, yn)).\n",
        "    # Let's split this up into our xs and our ys.\n",
        "    xs, ys = list(zip(*batch))\n",
        "    # Let's create a tensor that concatenates all our images on a new axis.\n",
        "    # Is there another way to do this?\n",
        "    xs = torch.cat([img_to_scaled_tensor(i).unsqueeze(0) for i in xs], dim=0)\n",
        "    # Let's create another tensor that combines all our class labels.\n",
        "    ys = torch.tensor([class_to_idx(i) for i in ys])\n",
        "\n",
        "    return xs, ys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4WZRrI2RMkG"
      },
      "outputs": [],
      "source": [
        "# Test the collate function\n",
        "items = (train_cifar[0], train_cifar[1])\n",
        "items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Yt5u64MRX_f"
      },
      "outputs": [],
      "source": [
        "x_b, y_b = collate_fn(items)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHuef7duRap2"
      },
      "outputs": [],
      "source": [
        "x_b.shape, y_b.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBx2hrMiPBwt"
      },
      "outputs": [],
      "source": [
        "train_cifar_dl = DataLoader(\n",
        "    train_cifar,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=N_WORKERS,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JEK0-_dPETh"
      },
      "outputs": [],
      "source": [
        "for x_b, y_b in train_cifar_dl:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IJw3fb5NGba",
        "outputId": "7a4ab849-02ee-483f-ebff-38083742bb50"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "x_b.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_rS_Q0bSL60P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjSj5gcVOpb9",
        "outputId": "1acd1b24-aaa5-4dfb-fc30-99339d680e3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "y_b.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGbVes-rSI9P"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "04_Torch_Data_API.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}